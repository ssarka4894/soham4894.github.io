<!DOCTYPE html>
<html>
    <head>
        <title>Soham Sarkar</title>
    </head>

    <style>
        h1 {
            margin-top: 0;
            margin-bottom: 0;
        }
        div {
            max-width: 960px;
            margin: auto;
        }
        td {
            valign: top;
            padding-bottom: 1em;
        }
        ul {
            margin-top: 0;
            margin-bottom: 0;
            padding-left: 1em;
        }
        h2 {
          overflow: hidden;
          text-align: center;
        }
        h2:before,
        h2:after {
          background-color: #000;
          content: "";
          display: inline-block;
          height: 1px;
          position: relative;
          vertical-align: middle;
          width: 50%;
        }
        h2:before {
          right: 0.5em;
          margin-left: -50%;
        }
        h2:after {
          left: 0.5em;
          margin-right: -50%;
        }
    </style>

    <body>
        <div>
            <table>
                <td width="230">
                    <img src="images/sarkar_portrait.jpg" alt="Fabio Pardo" height="250"/>
                </td>
                <td>
                    <h1>Soham Sarkar</h1>
                    <br>
                    PhD Student in Robotics<br>
                    <br>
                    Arizona State University<br>
                    Tempe <br>
                    United States of America<br>
                    <br>
                    <code>ssarka30.asu.edu</code><br>
                    <br>
                    <a href="https://github.com/ssarka4894"><img src="images/github.svg" alt="fabiopardo" height="50"/></a>
                    <a href="https://twitter.com/lets_keep_goin"><img src="images/twitter.svg" alt="@pardofab" height="50"/></a>
                </td>
            </table>
        </div>

        <div>
            <br>
            I am a PhD student in the
            <a href="https://www.imperial.ac.uk/robot-intelligence/">Robot Intelligence Lab</a> at
            <a href="https://www.imperial.ac.uk/">Imperial College London</a>.<br>
            My main research focuses on Deep Reinforcement Learning.<br><br>
        </div>

        <div>
            <h2>Education</h2>
            <table>
                <tr>
                    <td width="300">
                        <img src="images/asu_logo.png" height="80"/>
                    </td>
                    <td>
                        <b>2021 – present</b><br>
                        PhD in <b>Electrical Engineering</b><br>
                        Optimal Control, Reinforcement Learning<br>
                         @ Arizona State University, Tempe, Arizona, US
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/asu_logo.png" height="80"/>
                    </td>
                    <td>
                        <b>2018 – 2020</b><br>
                        Master's degree in <b>Mechanical Engineering</b><br>
                        Systems and Control Theory, Robotics<br>
                        @ Arizona State University, Tempe, Arizona, US
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/srmseal.png" height="80"/>
                    </td>
                    <td>
                        <b>2013 – 2017</b><br>
                        Undergraduate degree in <b>Mechatronics</b><br>
                        Control Systems, Mechanical Engineering<br>
                        @ SRM University, Kattankulathur, Tamil Nadu, India
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Teaching Experience</h2>
            <table>
                <tr>
                    <td width="300">
                        <img src="images/deepmind.png" height="40"/>
                    </td>
                    <td>
                        <b>2021</b><br>
                        <b>Learning to plan</b><br>
                        André Barreto, Théophane Weber, Arthur Guez, Peter Humphreys, Timothy Lillicrap, Mehdi Mirza<br>
                        @ DeepMind (Reinforcement Learning team), London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/deepmind.png" height="40"/>
                    </td>
                    <td>
                        <b>2019</b><br>
                        <b>Motor primitives and competitive self-play</b><br>
                        Raia Hadsell, Nicolas Heess, Josh Merel and Leonard Hasenclever<br>
                        @ DeepMind (Deep Learning team), London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/nii.png" height="30"/>
                    </td>
                    <td>
                        <b>2015</b><br>
                        <b>Deep reinforcement learning for autonomous robot navigation from vision</b><br>
                        Tetsunari Inamura<br>
                        @ National Institute of Informatics, Tokyo, Japan
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/flowers.png" height="32"/>
                    </td>
                    <td>
                        <b>2014</b><br>
                        <b>Multimodal concepts emergence for a humanoid robot in interaction with a human tutor</b><br>
                        David Filliat<br>
                        @ Flowers laboratory, Inria and ENSTA ParisTech, Paris, France<br>
                        <a href=https://youtu.be/Ym5aYfzoQX8>Video</a> and
                        <a href=https://youtu.be/i8xQaVQDfBQ>video</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/inria.png" height="30"/>
                    </td>
                    <td>
                        <b>2013</b><br>
                        <b>Optimal decision making based on a mixture of prediction experts</b><br>
                        <b>Homeostatic engine for reinforcement learning agents</b><br>
                        Laurent Orseau<br>
                        @ Inria and AgroParisTech, Paris, France
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/lip6.png" height="50"/>
                    </td>
                    <td>
                        <b>2013</b><br>
                        <b>Ontology visualization methods and their impact on short-term memory storage in humans</b><br>
                        Jean-Gabriel Ganascia<br>
                        @ Lip6, Paris, France
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Research</h2>
            <table>
                <tr>
                    <td width="300">
                        <img src="images/ostrichrl.gif" height="120"/>
                    </td>
                    <td>
                        <b>OstrichRL: A Musculoskeletal Ostrich Simulation to Study Bio-mechanical Locomotion</b><br>
                        Vittorio La Barbera*, Fabio Pardo*, Yuval Tassa, Monica Daley, Christopher Richards, Petar Kormushev, John Hutchinson (* equal contribution)<br>
                        @ NeurIPS' deep RL workshop 2021<br>
                        <a href="https://arxiv.org/abs/2112.06061">Paper</a>,
                        <a href="posters/ostrichrl.pdf">poster</a>,
                        <a href="https://sites.google.com/view/ostrichrl/home">Website</a> and
                        <a href="https://github.com/vittorione94/ostrichrl">code</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/ivy.png" height="80"/>
                    </td>
                    <td>
                        <b>Ivy: Templated Deep Learning for Inter-Framework Portability</b><br>
                        Daniel Lenton, Fabio Pardo, Fabian Falck, Stephen James, Ronald Clark<br>
                        <a href="https://arxiv.org/abs/2102.02886">Paper</a>,
                        <a href="https://ivy-dl.org/">website</a> and
                        <a href="https://github.com/ivy-dl/ivy">code</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/tonic.png" height="80"/><br><br>
                    </td>
                    <td>
                        <b>Tonic: A Deep Reinforcement Learning Library for Fast Prototyping and Benchmarking</b><br>
                        Fabio Pardo<br>
                        @ NeurIPS' deep RL workshop 2020<br>
                        <a href="https://arxiv.org/abs/2011.07537">Paper</a>,
                        <a href="posters/tonic.pdf">poster</a>,
                        <a href="https://github.com/fabiopardo/tonic">code</a> and
                        <a href="https://github.com/fabiopardo/tonic_data">data</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/comic.gif" height="100"/>
                    </td>
                    <td>
                        <b>CoMic: Complementary Task Learning & Mimicry for Reusable Skills</b><br>
                        Leonard Hasenclever, Fabio Pardo, Raia Hadsell, Nicolas Heess, Josh Merel<br>
                        @ ICML 2020<br>
                        <a href="http://proceedings.mlr.press/v119/hasenclever20a.html">Paper</a> and
                        <a href="https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/tasks/reference_pose">code</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/qmap_mario_montezuma.gif" height="200"/>
                    </td>
                    <td>
                        <b>Scaling All-Goals Updates in Reinforcement Learning Using Convolutional Neural Networks</b><br>
                        Fabio Pardo, Vitaly Levdik, Petar Kormushev<br>
                        @ AAAI 2020<br>
                        @ NeurIPS 2018 Deep RL Workshop<br>
                        @ ICML 2018 Exploration in RL Workshop<br>
                        <a href="https://arxiv.org/abs/1810.02927">Paper</a>,
                        <a href="posters/qmap.pdf">poster</a>,
                        <a href="https://sites.google.com/view/q-map-rl">website</a> and
                        <a href="https://github.com/fabiopardo/qmap">code</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/time_limits_std.png" height="80"/>
                        <img src="images/time_limits_ta.png" height="80"/>
                        <img src="images/time_limits_peb.png" height="80"/>
                    </td>
                    <td>
                        <b>Time Limits in Reinforcement Learning</b><br>
                        Fabio Pardo, Arash Tavakoli, Vitaly Levdik, Petar Kormushev<br>
                        @ ICML 2018<br>
                        @ NIPS 2017 Deep RL Symposium<br>
                        <a href="https://arxiv.org/abs/1712.00378">Paper</a>,
                        <a href="posters/time_limits_in_rl.pdf">poster</a> and
                        <a href="https://sites.google.com/view/time-limits-in-rl">website</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/branching.png" height="80"/>
                    </td>
                    <td>
                        <b>Action Branching Architectures for Deep Reinforcement Learning</b><br>
                        Arash Tavakoli, Fabio Pardo, Petar Kormushev<br>
                        @ AAAI 2018<br>
                        @ NIPS 2017 Deep RL Symposium<br>
                        <a href="https://arxiv.org/abs/1711.08946">Paper</a> and
                        <a href="posters/action_branching_architectures.pdf">poster</a>
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Miscellaneous</h2>
            <table>
                <tr>
                    <td width="300">
                        <img src="images/imperial.png" height="50"/>
                    </td>
                    <td>
                        <b>2018 – present</b><br>
                        <b>Organizer of Imperial's deep reinforcement learning reading group</b><br>
                        Weekly meetings to discuss papers (contact me if you want to join)<br>
                        @ Imperial College, London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/imperial.png" height="50"/>
                    </td>
                    <td>
                        <b>2016 – 2018</b><br>
                        <b>Graduate teaching assistant in Computing and Robotics</b><br>
                        Lectures, tutorials, exams<br>
                        @ Imperial College, London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/prologin.png" height="60"/>
                    </td>
                    <td>
                        <b>2011 and 2012</b><br>
                        <b>Twice finalist of Prologin, the French national programming contest</b><br>
                        Algorithmic tests and 36-hour hackathon<br>
                        @ École Polytechnique and EPITA, Paris, France
                    </td>
                </tr>
            </table>
        </div>
    </body>
</html>
